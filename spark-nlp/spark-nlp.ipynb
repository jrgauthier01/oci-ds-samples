{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a2e5d4",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c64854",
   "metadata": {},
   "source": [
    "**Developed on conda environment [PySpark 3.2 and Data Flow](https://docs.oracle.com/iaas/data-science/using/conda-pyspark-fam.htm) for CPU on Python 3.8**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd963f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "\n",
    "def prepare_command(command: dict) -> str:\n",
    "    \"\"\"Converts dictionary command to the string formatted commands.\"\"\"\n",
    "    return f'\\'{json.dumps(command)}\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48780d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(\"resource_principal\") # Supported values: resource_principal, api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\")\n",
    "#assuming you already have a dataflow-logs bucket created in the region where the cluster is running. \n",
    "#Otherwise specify the bucket where the stdout/err logs will be stored. \n",
    "logs_bucket_uri = \"oci://dataflow-logs@bigdatadatasciencelarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2fe32",
   "metadata": {},
   "source": [
    "# John Snow Labs Spark NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81380ce",
   "metadata": {},
   "source": [
    "If you need any pre-trained Spark NLP models, you will have to download them and unzip them in the conda environment folder. Data Flow does not support egress to the public internet. You cannot dynamically download pre-trained models from the internet in Data Flow sessions.\n",
    "However you can download pre-trained models from the model hub as zip [archives](https://nlp.johnsnowlabs.com/models) and then unzip the models in the conda environment folder. Download the example model [Explain Document DL Pipeline for English](https://nlp.johnsnowlabs.com/2021/03/23/explain_document_dl_en.html) and upload it into your notebook session. Or you can execute this cell and download a public model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ad4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "cd ~\n",
    "curl https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_dl_en_3.0.0_3.0_1616473268265.zip --output explain_document_dl_en_3.0.0_3.0_1616473268265.zip\n",
    "mkdir /home/datascience/conda/pyspark32_p38_cpu_v1/sparknlp-models\n",
    "unzip explain_document_dl_en_3.0.0_3.0_1616473268265.zip -d /home/datascience/conda/pyspark32_p38_cpu_v1/sparknlp-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb4c79",
   "metadata": {},
   "source": [
    "publish the conda environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a84ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "odsc conda publish -s pyspark32_p38_cpu_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110834a",
   "metadata": {},
   "source": [
    "Create the cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_conda_environment_uri = \"oci://conda-env-ds@bigdatadatasciencelarge/conda_environments/cpu/PySpark 3.2 and Data Flow/1.0/pyspark32_p38_cpu_v1#conda\"\n",
    "\n",
    "command = prepare_command({\n",
    "    \"compartmentId\": compartment_id,\n",
    "    \"displayName\": \"TestDataFlowSessionWithCustomCondaEnvironment\",\n",
    "    \"language\": \"PYTHON\",\n",
    "    \"sparkVersion\": \"3.2.1\",\n",
    "    \"numExecutors\":2,\n",
    "    \"driverShape\":\"VM.Standard.E4.Flex\",\n",
    "    \"executorShape\":\"VM.Standard.E4.Flex\",\n",
    "    \"driverShapeConfig\":{\"ocpus\":2,\"memoryInGBs\":32},\n",
    "    \"executorShapeConfig\":{\"ocpus\":2,\"memoryInGBs\":32},\n",
    "    \"logsBucketUri\": logs_bucket_uri,\n",
    "    \"type\": \"SESSION\",\n",
    "    \"configuration\":{\n",
    "        \"spark.archives\": custom_conda_environment_uri,\n",
    "        \"fs.oci.client.hostname\": \"https://objectstorage.us-ashburn-1.oraclecloud.com\",\n",
    "        \"spark.jars.ivy\":\"/opt/spark/work-dir/conda/.ivy2\",\n",
    "        \"spark.jars.packages\": \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.1.0\"\n",
    "    }})\n",
    "\n",
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212fb9d7",
   "metadata": {},
   "source": [
    "Try a simple annotation task: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    " \n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    " \n",
    "# Start SparkSession with Spark NLP\n",
    "# start() functions has 3 parameters: gpu, m1, and memory\n",
    "# sparknlp.start(gpu=True) will start the session with GPU support\n",
    "# sparknlp.start(m1=True) will start the session with macOS M1 support\n",
    "# sparknlp.start(memory=\"16G\") to change the default driver memory in SparkSession\n",
    "spark = sparknlp.start()\n",
    " \n",
    "# Download a pre-trained pipeline\n",
    "pipeline = PretrainedPipeline('explain_document_dl', lang='en', disk_location=\"/opt/spark/work-dir/conda/sparknlp-models/\")\n",
    " \n",
    "# Your testing dataset\n",
    "text = \"\"\"\n",
    "Lawrence Joseph Ellison (born August 17, 1944) is an American business magnate and investor who is the co-founder,\n",
    "executive chairman, chief technology officer (CTO) and former chief executive officer (CEO) of the\n",
    "American computer technology company Oracle Corporation.[2] As of September 2022, he was listed by\n",
    "Bloomberg Billionaires Index as the ninth-wealthiest person in the world, with an estimated\n",
    "fortune of $93 billion.[3] Ellison is also known for his 98% ownership stake in Lanai,\n",
    "the sixth-largest island in the Hawaiian Archipelago.[4]\n",
    "\"\"\"\n",
    " \n",
    "# Annotate your testing dataset\n",
    "result = pipeline.annotate(text)\n",
    " \n",
    "# What's in the pipeline\n",
    "print(list(result.keys()))\n",
    " \n",
    "# Check the results\n",
    "print(result['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a51d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1eef612",
   "metadata": {},
   "source": [
    "**Expected result:**\n",
    "<div class=\"cell border-box-sizing text_cell rendered\">\n",
    "    <div class=\"prompt input_prompt\"></div>\n",
    "    <div class=\"inner_cell\">\n",
    "        <div class=\"text_cell_render border-box-sizing rendered_html\">\n",
    "            <div class=\"alert alert-block alert-info\" style=\"background: none; border: 1px solid; padding: 10px\">\n",
    "                <b><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Info</b><br>\n",
    "<div style=\"padding:10px 0px\">\n",
    "\n",
    "```python\n",
    "['entities', 'stem', 'checked', 'lemma', 'document', 'pos', 'token', 'ner', 'embeddings', 'sentence']\n",
    "['Lawrence Joseph Ellison', 'American', 'American', 'Oracle Corporation', 'Bloomberg Billionaires Index', 'Ellison', 'Lanai', 'Hawaiian Archipelago']\n",
    "```\n",
    "</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c15f6",
   "metadata": {},
   "source": [
    "# Session Termination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%stop_session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v1]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
